#Example of performing a Data analysis on Spam emails and 
#Trying to predict spam emails

library(kernlab)
data(spam)

#Perform sampling (split the data set, us one set to build model
## use another set to determine how good model is.)

set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)

trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]

names(trainSpam)

#Type of email: Spam and Nonspam
table(trainSpam$type)

#Avg number of capital numbers
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)

#Corr bw a couple variables 
plot(log10(trainSpam[, 1:4] + 1))

#Clustering words together
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)

#Basic statistical model
#Calculating cross validated errors
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
  lmFormula = reformulate(names(trainSpam)[i], response = "numType")
  glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
  cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}

## Which predictor has minimul cross-validated error?
names(trainSpam)[which.min(cvError)]

#Running the logistic regression
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)

predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])

predictedSpam[predictionModel$fitted > 0.5] = "spam"

#predicted spam
table(predictedSpam, testSpam$type)
#Error rate: 22%
(61 + 458) / (1346 + 458 + 61 + 449)